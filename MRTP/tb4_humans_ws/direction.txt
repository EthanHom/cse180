My questions:
    Does this implementation follow what the MRTP textbook would recommend? 
    Is this implementation also correct?
    Are the results from the terminal correct?

Note: 
    From student: There’s a possibility your scanning results may be off if you’re using the laser scanner because it’s rotated 90 deg from the robot, it’s not perfectly straight
    From professor: some of you indicated today that the range finder may be oriented wrong on the robot. Upon further investigation I can affirm this is not the case. In particular, you have a sensor with a 360 field of view, so, so there is no "forward" direction. If you run

        ros2 topic echo /scan

        you can see that the sensor readings are with respect to the frame rplidar_link. The relative transformation between rplidar_link and base_link can be retrieved from /tf_static. Finally, as common for all laser scanners (you can confirm that with ros2 interface show sensor_msgs/msg/LaserScan) the zero angle is along the x axis of the frame of the sensor (that is rplidar_link) and readings are around the positive Z axis. Since angle_min is 0 (as you can see from ros2 topic echo /scan) it means that the first reading aligned with the x axis of the sensor frame and from there you go counterclockwise. I advise you inspect the configuration with Rviz to get a better idea.


Directions: 
    Important: The final project may be completed individually or in teams of up to three students (no exceptions). Team registration is available under the “Announcements” section.

    If you choose to work individually, no registration is required. Any student not listed on a team will automatically be considered to be working alone.

    All teams must be registered by December 5.

    Project presentations will take place during the last week of classes.

    Individual projects: Present during your assigned lab section.

    Team projects: Present in any of the lab sections assigned to your team (no exceptions).

    =============================================================================================

    First, make sure to get the latest version of the MRTP repository, because the files for the final project have just been added. After having rebuilt the MRTP workspace, you can launch the simulation environment as follows: 

    ros2 launch gazeboenvs tb4_warehouse.launch.py
    If you want to run both gazebo and rviz (useful for debugging), use the following command:

    ros2 launch gazeboenvs tb4_warehouse.launch.py use_rviz:=true
    Note that the robot starts with pose x=2.12, y=-21.3 and yaw = 1.57 (radians). The localization algorithm is initialized with these values.

    As you can see from Gazebo and Rviz, the robot is operating in a warehouse environment in which there are two stationary human characters. The footprint of the humans is included in the map loaded in gazebo, and available to the robot through the /map topic. Your task is to write a controller for the robot to determine

    if the humans have move to a different location;
    in case they have moved, determine where they are. Note that if the characters have moved, the will be permanently relocated at a different position, but they will not keep moving.
    To solve this problem you should:

    use the navigation library provided in class to move the robot in the environment using the nav2 stack
    retrieve the map of the environment from /map
    use the range finder on top of the robot to check if the environment have changed (e.g., if the humans have moved).
    use the topic amcl_pose to retrieve the position of the robot in the environment
    Deliverables:

    zipped file with code (included in a self contained workspace); to be uploaded to catcourses;
    one pager description of the solution (pdf); to be uploaded to catcourses;
    presentation with demo to be given during lab hours.
    

    Q&A:

    Q: What does it mean that I have to submit a fully contained file?
    A: It means that the zipped file you submit must have a workspace, and inside the workspace it must have all code you developed (located in a suitable package). If your code relies on additional ros2 standard packages (i.e., packages that can be installed with atp install) you should list them. If the packages are not standard (e.g., downloaded from github), please include them in your submission. 
    Q: How can I alter the position of the characters to test if my solution works?
    A: Start the simulation environment in Gazebo and identify the character you intend to move. Click on it with the mouse to select it. A white parallelepiped will appear around the character, indicating that it has been selected. In the upper right corner of the screen, open the “Pose” menu. From there, you can modify the character’s x, y, and z coordinates, as well as its roll, pitch, and yaw. Please note that changes take effect only after you press the Tab key or select a different item in the menu.
    Q: I want to know that if our entire group must be present during the demo and presentation. We all have different sections that conflict with other classes so we would have to forego one of our other responsibilities to make it to any of the other lab sections.
    A: It is not necessary for the entire team to be present during the demo and presentation. One (or two) of you can make the presentation during any of the lab sections you registered for.
    Q: What is the format of the presentation?
    A: You build and run the code in front of the TA and describe how you solved the problem, answering any question the TA may have. The presentation is not in front of the class and you do not have to present slides.

KNOWN OBSTACTLES:
    SHELF_BIG_0: (x: -8.5, y: -13)
    SHELF_BIG_1: (x: 6.5, y: -13)
    SHELF_BIG_2: (x: -1.5, y: -13)
    SHELF_3: (x: 13.5, y: 4.5)
    SHELF_4: (x: 10, y: 4.5)
    SHELF_5: (x: 13.5, y: -21)
    SHELF_6: (x: 13.5, y: -15)
    SHELF_7: (x: 0.4, y: -2)
    SHELF_BIG_3: (x: 3.5, y: 9.5, yaw(rad): 1.57)
    SHELF_BIG_4: (x: -1.3, y: 18.5, yaw(rad): 1.57)
    SHELF_0: (x: -10, y: 21.5, yaw(rad): 1.57)
    SHELF_1: (x: -7, y: 23.6, yaw(rad): 1.57)
    SHELF_2: (x: -4, y: 21.5, yaw(rad): 1.57)
    BARRIER_0: (x: -10.4, y: 14.75, yaw(rad): 1.57)
    BARRIER_1: (x: -10.4, y: 10.5, yaw(rad): 1.57)
    BARRIER_2: (x: -10.4, y: 6.5, yaw(rad): 1.57)
    BARRIER_3: (x: -12.85, y: 4.85)
    CHAIR_0: (x: 14.3, y: -5.5, yaw(rad): 3)
    CHAIR_1: (x: 14.3, y: -4, yaw(rad): -3)
    FCHAIR_0: (x: -11.5, y: 6.4, yaw(rad): -1.8)
    FCHAIR1: (x: -14, y: 6.5, yaw(rad): 1.9)
    TABLE0: (x: -12.7, y: 6.5)

Corners of the warehouse (estimated and based on my screenshot of map):
    (-14, 24) - TOP LEFT 
    (14, 24) - TOP RIGHT
    (-14, -24) - BOTTOM LEFT
    (14, -24) - BOTTOM RIGHT
    (in the middle of the grid, that is (0,0).)

Where Humans are located when not moved:
    human1 - (1.00, -1.00)
    human2 - (-12.00, 15.00)


Terminal Results For my test cases:
    Human 1 and 2 not moved:

    Human 1 at (5,3):
    
    Human 1 at (10,12):

    Human 1 at (-4,-10):
        Here

    Human 2 at (12,11):

    Human 1 at (-7, 12):

    Human 2 at (-12, 2):

    Human 1 at (-12, -23):

    Human 2 at (12,0):

    Human 1 at (12,-12):

    Human 2 at (13,-18):

    Human 1 at (14,-24):

    Human 2 at (-13,9):

    Human 1 at (-13,9): 

    Human 1 at (2,-12), Human 2 at (-6,14):
