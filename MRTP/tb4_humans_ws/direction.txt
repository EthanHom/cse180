My questions:
    Does this implementation follow what the MRTP textbook would recommend? 
    Is this implementation also correct?
    Are the results from the terminal correct?

Note: 
    From student: There’s a possibility your scanning results may be off if you’re using the laser scanner because it’s rotated 90 deg from the robot, it’s not perfectly straight
    From professor: some of you indicated today that the range finder may be oriented wrong on the robot. Upon further investigation I can affirm this is not the case. In particular, you have a sensor with a 360 field of view, so, so there is no "forward" direction. If you run

        ros2 topic echo /scan

        you can see that the sensor readings are with respect to the frame rplidar_link. The relative transformation between rplidar_link and base_link can be retrieved from /tf_static. Finally, as common for all laser scanners (you can confirm that with ros2 interface show sensor_msgs/msg/LaserScan) the zero angle is along the x axis of the frame of the sensor (that is rplidar_link) and readings are around the positive Z axis. Since angle_min is 0 (as you can see from ros2 topic echo /scan) it means that the first reading aligned with the x axis of the sensor frame and from there you go counterclockwise. I advise you inspect the configuration with Rviz to get a better idea.

Directions: 
    Important: The final project may be completed individually or in teams of up to three students (no exceptions). Team registration is available under the “Announcements” section.

    If you choose to work individually, no registration is required. Any student not listed on a team will automatically be considered to be working alone.

    All teams must be registered by December 5.

    Project presentations will take place during the last week of classes.

    Individual projects: Present during your assigned lab section.

    Team projects: Present in any of the lab sections assigned to your team (no exceptions).

    =============================================================================================

    First, make sure to get the latest version of the MRTP repository, because the files for the final project have just been added. After having rebuilt the MRTP workspace, you can launch the simulation environment as follows: 

    ros2 launch gazeboenvs tb4_warehouse.launch.py
    If you want to run both gazebo and rviz (useful for debugging), use the following command:

    ros2 launch gazeboenvs tb4_warehouse.launch.py use_rviz:=true
    Note that the robot starts with pose x=2.12, y=-21.3 and yaw = 1.57 (radians). The localization algorithm is initialized with these values.

    As you can see from Gazebo and Rviz, the robot is operating in a warehouse environment in which there are two stationary human characters. The footprint of the humans is included in the map loaded in gazebo, and available to the robot through the /map topic. Your task is to write a controller for the robot to determine

    if the humans have move to a different location;
    in case they have moved, determine where they are. Note that if the characters have moved, the will be permanently relocated at a different position, but they will not keep moving.
    To solve this problem you should:

    use the navigation library provided in class to move the robot in the environment using the nav2 stack
    retrieve the map of the environment from /map
    use the range finder on top of the robot to check if the environment have changed (e.g., if the humans have moved).
    use the topic amcl_pose to retrieve the position of the robot in the environment
    Deliverables:

    zipped file with code (included in a self contained workspace); to be uploaded to catcourses;
    one pager description of the solution (pdf); to be uploaded to catcourses;
    presentation with demo to be given during lab hours.
    

    Q&A:

    Q: What does it mean that I have to submit a fully contained file?
    A: It means that the zipped file you submit must have a workspace, and inside the workspace it must have all code you developed (located in a suitable package). If your code relies on additional ros2 standard packages (i.e., packages that can be installed with atp install) you should list them. If the packages are not standard (e.g., downloaded from github), please include them in your submission. 
    Q: How can I alter the position of the characters to test if my solution works?
    A: Start the simulation environment in Gazebo and identify the character you intend to move. Click on it with the mouse to select it. A white parallelepiped will appear around the character, indicating that it has been selected. In the upper right corner of the screen, open the “Pose” menu. From there, you can modify the character’s x, y, and z coordinates, as well as its roll, pitch, and yaw. Please note that changes take effect only after you press the Tab key or select a different item in the menu.
    Q: I want to know that if our entire group must be present during the demo and presentation. We all have different sections that conflict with other classes so we would have to forego one of our other responsibilities to make it to any of the other lab sections.
    A: It is not necessary for the entire team to be present during the demo and presentation. One (or two) of you can make the presentation during any of the lab sections you registered for.
    Q: What is the format of the presentation?
    A: You build and run the code in front of the TA and describe how you solved the problem, answering any question the TA may have. The presentation is not in front of the class and you do not have to present slides.

KNOWN OBSTACTLES:
    SHELF_BIG_0: (x: -8.5, y: -13)
    SHELF_BIG_1: (x: 6.5, y: -13)
    SHELF_BIG_2: (x: -1.5, y: -13)
    SHELF_3: (x: 13.5, y: 4.5)
    SHELF_4: (x: 10, y: 4.5)
    SHELF_5: (x: 13.5, y: -21)
    SHELF_6: (x: 13.5, y: -15)
    SHELF_7: (x: 0.4, y: -2)
    SHELF_BIG_3: (x: 3.5, y: 9.5, yaw(rad): 1.57)
    SHELF_BIG_4: (x: -1.3, y: 18.5, yaw(rad): 1.57)
    SHELF_0: (x: -10, y: 21.5, yaw(rad): 1.57)
    SHELF_1: (x: -7, y: 23.6, yaw(rad): 1.57)
    SHELF_2: (x: -4, y: 21.5, yaw(rad): 1.57)
    BARRIER_0: (x: -10.4, y: 14.75, yaw(rad): 1.57)
    BARRIER_1: (x: -10.4, y: 10.5, yaw(rad): 1.57)
    BARRIER_2: (x: -10.4, y: 6.5, yaw(rad): 1.57)
    BARRIER_3: (x: -12.85, y: 4.85)
    CHAIR_0: (x: 14.3, y: -5.5, yaw(rad): 3)
    CHAIR_1: (x: 14.3, y: -4, yaw(rad): -3)
    FCHAIR_0: (x: -11.5, y: 6.4, yaw(rad): -1.8)
    FCHAIR1: (x: -14, y: 6.5, yaw(rad): 1.9)
    TABLE0: (x: -12.7, y: 6.5)

Corners of the warehouse (estimated and based on my screenshot of map):
    (-14, 24) - TOP LEFT 
    (14, 24) - TOP RIGHT
    (-14, -24) - BOTTOM LEFT
    (14, -24) - BOTTOM RIGHT
    (in the middle of the grid, that is (0,0).)

Where Humans are located when not moved:
    human1 - (1.00, -1.00)
    human2 - (-12.00, 15.00)


Terminal Results For my test cases:
    Human 1 and 2 not moved:

    Human 1 at (5,3):

    Human 1 at (10,12):

    Human 1 at (-4,-10):
        pc (linux): 

    Human 2 at (12,11):

    Human 1 at (-7, 12):

    Human 2 at (-12, 2):
        pc (linux):

    Human 1 at (-12, -23):

    Human 2 at (12,0):

    Human 2 at (-12,0):
    
    Human 1 at (12,-12): 

    Human 2 at (13,-18):
        mac:

    Human 1 at (14,-24):

    Human 2 at (-13,9):

    Human 1 at (-13,9):

    Human 1 at (2,-12), Human 2 at (-6,14):



 Code that worked but had issues with sometimes thinking human 1 was at original location when it wasnt. but when it didnt detect human 1 at original location, 100% found the new location:
        #include <memory>
        #include <vector>
        #include <cmath>
        #include <iostream>
        #include <chrono>
        #include <thread>
        #include <mutex>
        #include <atomic>
        #include <map>
        #include <algorithm>
        #include <limits>
        #include <iomanip>

        #include "rclcpp/rclcpp.hpp"
        #include "rclcpp_action/rclcpp_action.hpp"
        #include "sensor_msgs/msg/laser_scan.hpp"
        #include "nav_msgs/msg/occupancy_grid.hpp"
        #include "geometry_msgs/msg/pose.hpp"
        #include "geometry_msgs/msg/pose_stamped.hpp"
        #include "geometry_msgs/msg/pose_with_covariance_stamped.hpp"
        #include "geometry_msgs/msg/point_stamped.hpp"
        #include "tf2_ros/transform_listener.h"
        #include "tf2_ros/buffer.h"
        #include "tf2_geometry_msgs/tf2_geometry_msgs.hpp"
        #include "navigation/navigation.hpp" 

        struct DetectionCluster {
            double x, y;
            int count;
        };

        class HumanDetector : public rclcpp::Node {
        public:
            HumanDetector()
                : Node("tb4_human_detector"),
                tf_buffer_(this->get_clock()),
                tf_listener_(tf_buffer_)
            {
                if (!this->has_parameter("use_sim_time")) {
                    this->declare_parameter("use_sim_time", true);
                }
                this->set_parameter(rclcpp::Parameter("use_sim_time", true));

                map_sub_ = this->create_subscription<nav_msgs::msg::OccupancyGrid>(
                    "/map", rclcpp::QoS(1).transient_local().reliable(),
                    std::bind(&HumanDetector::mapCallback, this, std::placeholders::_1));

                scan_sub_ = this->create_subscription<sensor_msgs::msg::LaserScan>(
                    "/scan", rclcpp::SensorDataQoS(),
                    std::bind(&HumanDetector::scanCallback, this, std::placeholders::_1));

                amcl_sub_ = this->create_subscription<geometry_msgs::msg::PoseWithCovarianceStamped>(
                    "/amcl_pose", 10,
                    std::bind(&HumanDetector::amclCallback, this, std::placeholders::_1));

                RCLCPP_INFO(this->get_logger(), "Precision Human Detector Initialized.");
            }

            bool hasMap() const { return have_map_.load(); }
            
            bool isHuman1AtStart() const { 
                return (scans_near_h1_ > 20 && ((double)h1_hits_ / scans_near_h1_) > 0.1); 
            }
            
            bool isHuman2AtStart() const { 
                return (scans_near_h2_ > 20 && ((double)h2_hits_ / scans_near_h2_) > 0.1); 
            }

            std::pair<double, double> getBestNewCandidate() {
                std::lock_guard<std::mutex> lock(data_mutex_);
                
                std::vector<DetectionCluster> candidates;
                for (const auto& [coord, count] : dynamic_obstacles_) {
                    // Threshold: 40 hits
                    if (count < 40) continue; 
                    
                    double wx = coord.first / 10.0; 
                    double wy = coord.second / 10.0;

                    if (std::hypot(wx - H1_X, wy - H1_Y) < 2.0) continue;
                    if (std::hypot(wx - H2_X, wy - H2_Y) < 2.0) continue;
                    
                    // [FIX] TIGHTER BOUNDS
                    // Rejects walls at +/- 14.8 or +/- 24.7 while keeping humans at 14.0/24.0
                    if (wx < -14.6 || wx > 14.6 || wy < -24.6 || wy > 24.6) continue;

                    candidates.push_back({wx, wy, count});
                }

                std::sort(candidates.begin(), candidates.end(), 
                    [](const DetectionCluster &a, const DetectionCluster &b) { return a.count > b.count; });

                if (candidates.empty()) return {0.0, 0.0};
                return {candidates[0].x, candidates[0].y};
            }
            
            void clearCandidate(double x, double y) {
                std::lock_guard<std::mutex> lock(data_mutex_);
                for (auto it = dynamic_obstacles_.begin(); it != dynamic_obstacles_.end();) {
                    double wx = it->first.first / 10.0;
                    double wy = it->first.second / 10.0;
                    // Clear larger radius to wipe the false positive
                    if (std::hypot(wx - x, wy - y) < 2.0) {
                        it = dynamic_obstacles_.erase(it);
                    } else {
                        ++it;
                    }
                }
            }

            int8_t getMapValue(double x, double y) {
                std::lock_guard<std::mutex> lock(map_mutex_);
                if (!have_map_) return -1;
                int grid_x = static_cast<int>((x - map_.info.origin.position.x) / map_.info.resolution);
                int grid_y = static_cast<int>((y - map_.info.origin.position.y) / map_.info.resolution);
                if (grid_x < 0 || grid_x >= (int)map_.info.width || grid_y < 0 || grid_y >= (int)map_.info.height) return -1; 
                return map_.data[grid_y * map_.info.width + grid_x];
            }

            std::vector<geometry_msgs::msg::PoseStamped> generateCoveragePath() {
                std::vector<geometry_msgs::msg::PoseStamped> goals;
                std::lock_guard<std::mutex> lock(map_mutex_); 
                if (!have_map_) return goals;

                double step_size = 3.5; 
                
                auto is_free_unsafe = [&](double wx, double wy) {
                    int grid_x = static_cast<int>((wx - map_.info.origin.position.x) / map_.info.resolution);
                    int grid_y = static_cast<int>((wy - map_.info.origin.position.y) / map_.info.resolution);
                    if (grid_x < 0 || grid_x >= (int)map_.info.width || grid_y < 0 || grid_y >= (int)map_.info.height) return false; 
                    return map_.data[grid_y * map_.info.width + grid_x] == 0;
                };

                for (double y = map_.info.origin.position.y + 2.0; y < (map_.info.origin.position.y + (map_.info.height * map_.info.resolution)); y += step_size) {
                    for (double x = map_.info.origin.position.x + 2.0; x < (map_.info.origin.position.x + (map_.info.width * map_.info.resolution)); x += step_size) {
                        if (is_free_unsafe(x, y) && is_free_unsafe(x + 0.3, y) && is_free_unsafe(x - 0.3, y)) {
                            geometry_msgs::msg::PoseStamped p;
                            p.header.frame_id = "map";
                            p.pose.position.x = x;
                            p.pose.position.y = y;
                            p.pose.orientation.w = 1.0;
                            goals.push_back(p);
                        }
                    }
                }

                if (goals.empty()) return goals;
                double current_x = current_pose_.position.x;
                double current_y = current_pose_.position.y;
                std::vector<geometry_msgs::msg::PoseStamped> sorted_goals;
                std::vector<geometry_msgs::msg::PoseStamped> remaining = goals;

                while (!remaining.empty()) {
                    auto nearest_it = remaining.begin();
                    double min_dist = std::numeric_limits<double>::max();
                    for (auto it = remaining.begin(); it != remaining.end(); ++it) {
                        double d = std::hypot(it->pose.position.x - current_x, it->pose.position.y - current_y);
                        if (d < min_dist) { min_dist = d; nearest_it = it; }
                    }
                    sorted_goals.push_back(*nearest_it);
                    current_x = nearest_it->pose.position.x;
                    current_y = nearest_it->pose.position.y;
                    remaining.erase(nearest_it);
                }
                return sorted_goals;
            }

            void reportFindings(const std::vector<std::pair<double, double>>& verified_locs) {
                bool h1_found = isHuman1AtStart();
                bool h2_found = isHuman2AtStart();

                std::cout << "\n========================================" << std::endl;
                std::cout << "       HUMAN DETECTION REPORT" << std::endl;
                std::cout << "========================================" << std::endl;

                if (h1_found) {
                    std::cout << "[Human 1] STILL AT ORIGINAL (" << H1_X << ", " << H1_Y << ") [DETECTED]" << std::endl;
                } else {
                    std::cout << "[Human 1] MOVED from (" << H1_X << ", " << H1_Y << ")" << std::endl;
                    if (!verified_locs.empty()) {
                        std::cout << "          NEW LOCATION: (" << verified_locs[0].first << ", " << verified_locs[0].second << ")" << std::endl;
                    } else {
                        std::cout << "          NEW LOCATION: Not found" << std::endl;
                    }
                }

                if (h2_found) {
                    std::cout << "[Human 2] STILL AT ORIGINAL (" << H2_X << ", " << H2_Y << ") [DETECTED]" << std::endl;
                } else {
                    std::cout << "[Human 2] MOVED from (" << H2_X << ", " << H2_Y << ")" << std::endl;
                    size_t idx = (!h1_found && verified_locs.size() > 1) ? 1 : 0;
                    if (verified_locs.size() > idx) {
                        std::cout << "          NEW LOCATION: (" << verified_locs[idx].first << ", " << verified_locs[idx].second << ")" << std::endl;
                    } else {
                        std::cout << "          NEW LOCATION: Not found" << std::endl;
                    }
                }
                std::cout << "========================================\n" << std::endl;
            }

            const double H1_X = 1.0, H1_Y = -1.0;
            const double H2_X = -12.0, H2_Y = 15.0;

        private:
            rclcpp::Subscription<nav_msgs::msg::OccupancyGrid>::SharedPtr map_sub_;
            rclcpp::Subscription<sensor_msgs::msg::LaserScan>::SharedPtr scan_sub_;
            rclcpp::Subscription<geometry_msgs::msg::PoseWithCovarianceStamped>::SharedPtr amcl_sub_;

            nav_msgs::msg::OccupancyGrid map_;
            std::atomic<bool> have_map_{false};
            std::atomic<bool> is_localized_{false};
            
            std::mutex map_mutex_;
            std::mutex data_mutex_;
            std::mutex pose_mutex_;
            
            geometry_msgs::msg::Pose current_pose_;
            tf2_ros::Buffer tf_buffer_;
            tf2_ros::TransformListener tf_listener_;

            int scans_near_h1_{0}, h1_hits_{0};
            int scans_near_h2_{0}, h2_hits_{0};

            std::map<std::pair<int,int>, int> dynamic_obstacles_;

            void mapCallback(const nav_msgs::msg::OccupancyGrid::SharedPtr msg) {
                std::lock_guard<std::mutex> lock(map_mutex_);
                map_ = *msg;
                have_map_.store(true);
            }

            void amclCallback(const geometry_msgs::msg::PoseWithCovarianceStamped::SharedPtr msg) {
                std::lock_guard<std::mutex> lock(pose_mutex_);
                current_pose_ = msg->pose.pose;
                is_localized_.store(true);
            }

            void scanCallback(const sensor_msgs::msg::LaserScan::SharedPtr scan) {
                if (!have_map_.load() || !is_localized_.load()) return;

                geometry_msgs::msg::TransformStamped tf;
                try {
                    tf = tf_buffer_.lookupTransform("map", scan->header.frame_id, tf2::TimePointZero);
                } catch (const tf2::TransformException &ex) { return; }

                double rx = tf.transform.translation.x;
                double ry = tf.transform.translation.y;

                bool near_h1 = std::hypot(rx - H1_X, ry - H1_Y) < 3.5;
                bool near_h2 = std::hypot(rx - H2_X, ry - H2_Y) < 3.5;

                if (near_h1) scans_near_h1_++;
                if (near_h2) scans_near_h2_++;

                bool h1_hit_this_scan = false;
                bool h2_hit_this_scan = false;

                auto get_map_val_unsafe = [&](double x, double y) -> int {
                    int gx = static_cast<int>((x - map_.info.origin.position.x) / map_.info.resolution);
                    int gy = static_cast<int>((y - map_.info.origin.position.y) / map_.info.resolution);
                    if (gx < 0 || gx >= (int)map_.info.width || gy < 0 || gy >= (int)map_.info.height) return -1;
                    return map_.data[gy * map_.info.width + gx];
                };

                std::lock_guard<std::mutex> lock(map_mutex_);

                for (size_t i = 0; i < scan->ranges.size(); ++i) {
                    float r = scan->ranges[i];
                    if (!std::isfinite(r) || r < scan->range_min || r > 4.5) continue; 

                    float angle = scan->angle_min + i * scan->angle_increment;
                    geometry_msgs::msg::PointStamped p_laser, p_map;
                    p_laser.header = scan->header;
                    p_laser.point.x = r * std::cos(angle);
                    p_laser.point.y = r * std::sin(angle);
                    p_laser.point.z = 0.0;

                    tf2::doTransform(p_laser, p_map, tf);
                    double wx = p_map.point.x;
                    double wy = p_map.point.y;

                    if (near_h1 && std::hypot(wx - H1_X, wy - H1_Y) < 0.6) h1_hit_this_scan = true;
                    if (near_h2 && std::hypot(wx - H2_X, wy - H2_Y) < 0.6) h2_hit_this_scan = true;

                    int map_val = get_map_val_unsafe(wx, wy);
                    bool wall_nearby = false;
                    int gx = static_cast<int>((wx - map_.info.origin.position.x) / map_.info.resolution);
                    int gy = static_cast<int>((wy - map_.info.origin.position.y) / map_.info.resolution);
                    
                    // [FIX] INCREASED WALL BUFFER
                    // 16 cells * 0.03m = 48cm radius.
                    // Prevents pole/barrier detection as humans (fixes your issue).
                    int check_rad = 16; 
                    
                    for(int dy=-check_rad; dy<=check_rad && !wall_nearby; ++dy) {
                        for(int dx=-check_rad; dx<=check_rad && !wall_nearby; ++dx) {
                            int idx = (gy + dy) * map_.info.width + (gx + dx);
                            
                            if (idx >= 0 && idx < (int)map_.data.size()) {
                                int8_t val = map_.data[idx];
                                if (val > 50 || val == -1) {
                                    wall_nearby = true;
                                }
                            }
                        }
                    }

                    if (map_val == 0 && !wall_nearby && r < 4.0) {
                        std::lock_guard<std::mutex> data_lock(data_mutex_);
                        int key_x = static_cast<int>(std::round(wx * 10));
                        int key_y = static_cast<int>(std::round(wy * 10));
                        dynamic_obstacles_[{key_x, key_y}]++;
                    }
                }

                if (h1_hit_this_scan) h1_hits_++;
                if (h2_hit_this_scan) h2_hits_++;
            }
        };

        int main(int argc, char **argv) {
            rclcpp::init(argc, argv);
            auto detector = std::make_shared<HumanDetector>();
            Navigator navigator(true);
            std::thread spin_thread([&]() { rclcpp::spin(detector); });

            auto start_time = std::chrono::high_resolution_clock::now();

            std::cout << "\n[Main] Waiting for Map..." << std::endl;
            while (rclcpp::ok() && !detector->hasMap()) { std::this_thread::sleep_for(std::chrono::milliseconds(100)); }
            std::cout << "[Main] Map Received." << std::endl;

            auto init_pose = std::make_shared<geometry_msgs::msg::Pose>();
            init_pose->position.x = 2.12; init_pose->position.y = -21.3;
            init_pose->orientation.z = 0.7071; init_pose->orientation.w = 0.7071;
            navigator.SetInitialPose(init_pose);
            navigator.WaitUntilNav2Active();

            // PHASE 1: CHECK ORIGINAL SPOTS
            std::cout << "\n[Main] Phase 1: Checking original locations..." << std::endl;
            
            auto h1_goal = std::make_shared<geometry_msgs::msg::Pose>();
            h1_goal->position.x = detector->H1_X + 1.5; h1_goal->position.y = detector->H1_Y; h1_goal->orientation.w = 1.0;
            navigator.GoToPose(h1_goal);
            while (rclcpp::ok() && !navigator.IsTaskComplete()) { std::this_thread::sleep_for(std::chrono::milliseconds(100)); }
            navigator.Spin(); 
            while (rclcpp::ok() && !navigator.IsTaskComplete()) { std::this_thread::sleep_for(std::chrono::milliseconds(100)); }

            auto h2_goal = std::make_shared<geometry_msgs::msg::Pose>();
            h2_goal->position.x = detector->H2_X + 1.5; h2_goal->position.y = detector->H2_Y; h2_goal->orientation.w = 1.0;
            navigator.GoToPose(h2_goal);
            while (rclcpp::ok() && !navigator.IsTaskComplete()) { std::this_thread::sleep_for(std::chrono::milliseconds(100)); }
            navigator.Spin();
            while (rclcpp::ok() && !navigator.IsTaskComplete()) { std::this_thread::sleep_for(std::chrono::milliseconds(100)); }

            bool h1_found = detector->isHuman1AtStart();
            bool h2_found = detector->isHuman2AtStart();
            int missing_count = (h1_found ? 0 : 1) + (h2_found ? 0 : 1);

            std::cout << "[Main] Status: H1@" << (h1_found ? "Start" : "Moved") 
                    << ", H2@" << (h2_found ? "Start" : "Moved") << std::endl;

            // PHASE 2: VERIFIED SEARCH
            std::vector<std::pair<double, double>> verified_locations;

            if (missing_count == 0) {
                std::cout << "[Main] SUCCESS: Both humans found at original locations!" << std::endl;
            } 
            else {
                std::cout << "[Main] WARNING: Need to find " << missing_count << " more human(s). Starting Search..." << std::endl;
                
                auto waypoints = detector->generateCoveragePath();
                int wp_count = 0;

                for (const auto& wp : waypoints) {
                    if (verified_locations.size() >= static_cast<size_t>(missing_count)) break;

                    std::pair<double, double> cand = detector->getBestNewCandidate();
                    
                    if (cand.first != 0.0) {
                        bool already_checked = false;
                        for(auto loc : verified_locations) {
                            if(std::hypot(cand.first - loc.first, cand.second - loc.second) < 2.0) already_checked = true;
                        }

                        if (!already_checked) {
                            std::cout << "\n[Main] INTERRUPT: Investigating candidate at (" << cand.first << ", " << cand.second << ")..." << std::endl;
                            navigator.CancelTask(); 
                            
                            auto cand_goal = std::make_shared<geometry_msgs::msg::Pose>();
                            cand_goal->position.x = cand.first; 
                            cand_goal->position.y = cand.second; 
                            cand_goal->orientation.w = 1.0;

                            navigator.GoToPose(cand_goal);
                            while (rclcpp::ok() && !navigator.IsTaskComplete()) { std::this_thread::sleep_for(std::chrono::milliseconds(100)); }
                            navigator.Spin(); 
                            while (rclcpp::ok() && !navigator.IsTaskComplete()) { std::this_thread::sleep_for(std::chrono::milliseconds(100)); }

                            std::pair<double, double> confirmed = detector->getBestNewCandidate();
                            
                            if (confirmed.first != 0.0 && std::hypot(confirmed.first - cand.first, confirmed.second - cand.second) < 1.0) {
                                std::cout << "[Main] CONFIRMED HUMAN FOUND!" << std::endl;
                                verified_locations.push_back(cand);
                            } else {
                                std::cout << "[Main] False positive (Ghost/Wall). Clearing and resuming..." << std::endl;
                                detector->clearCandidate(cand.first, cand.second);
                            }
                            continue; 
                        }
                    }

                    wp_count++;
                    if (std::hypot(wp.pose.position.x - 2.12, wp.pose.position.y - (-21.3)) < 2.0) continue;

                    std::cout << "[Main] Navigating to WP " << wp_count << "/" << waypoints.size() << "..." << std::flush;
                    auto goal = std::make_shared<geometry_msgs::msg::Pose>(wp.pose);
                    navigator.GoToPose(goal);
                    
                    while (rclcpp::ok() && !navigator.IsTaskComplete()) { 
                        std::pair<double, double> mid_cand = detector->getBestNewCandidate();
                        if (mid_cand.first != 0.0) {
                            bool known = false;
                            for(auto loc : verified_locations) if(std::hypot(mid_cand.first - loc.first, mid_cand.second - loc.second) < 2.0) known = true;
                            if(!known) {
                                navigator.CancelTask();
                                break; 
                            }
                        }
                        std::this_thread::sleep_for(std::chrono::milliseconds(100)); 
                    }

                    if (navigator.GetResult() == rclcpp_action::ResultCode::SUCCEEDED) {
                        std::cout << " DONE" << std::endl;
                    } else {
                        std::cout << " INTERRUPTED/SKIPPED" << std::endl;
                    }
                }
            }

            auto end_time = std::chrono::high_resolution_clock::now();
            auto duration_sec = std::chrono::duration_cast<std::chrono::seconds>(end_time - start_time);
            int total_seconds = static_cast<int>(duration_sec.count());
            int minutes = total_seconds / 60;
            int seconds = total_seconds % 60;

            detector->reportFindings(verified_locations);
            std::cout << "[Main] Mission Completed in " << minutes << " min " << seconds << " sec." << std::endl;

            rclcpp::shutdown();
            spin_thread.join();
            return 0;
        }
